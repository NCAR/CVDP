{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b36ace1-1eb2-4835-8826-a683e83c4a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import xarray as xr \n",
    "import numpy as np\n",
    "import glob\n",
    "import functions as func\n",
    "import calendar as calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc4df6e-3b25-431f-8e31-76d7cf9a1133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "40\n",
      "/project/mojave/cmip6/historical/{Amon,Omon}/psl/CESM2/r1i1p1f1/gn/*.nc\n",
      "More than one set of { } syntax found in entry in namelist, only one set of { } allowed per row, exiting\n",
      "/project/mojave/cmip6/ssp370/{Amon,Omon}/psl/CESM2/r1i1p1f1/gn/*.nc\n",
      "More than one set of { } syntax found in entry in namelist, only one set of { } allowed per row, exiting\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "pa = \"/project/mojave/cmip6/{historical,ssp370}/{Amon,Omon}/psl/CESM2/r1i1p1f1/gn/*.nc\"\n",
    "si = pa.find('{')\n",
    "if si != -1:    # { } syntax found, search accordingly\n",
    "    ei = pa.find('}')\n",
    "    fl = pa[si+1:ei].split(',')\n",
    "    print(si)\n",
    "    print(ei)\n",
    "    files_list = []\n",
    "    for ext in fl:\n",
    "        print(pa[:si]+ext+pa[ei+1:])\n",
    "        test = pa[:si]+ext+pa[ei+1:]\n",
    "        si2 = test.find('{')\n",
    "        if si2 != -1:\n",
    "            print(\"More than one set of { } syntax found in entry in namelist, only one set of { } allowed per row, exiting\")\n",
    "            exit()\n",
    "        files_list.extend(glob.glob(pa[:si]+ext+pa[ei+1:]))\n",
    "else:    \n",
    "    files_list = glob.glob(pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "270f528c-87b1-4a6a-ab2b-214aea057616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCAR.cvdp_data.prect.ensemble_mean.1979-2018.nc\n",
      "('PRECC', 'PRECL', 'PRECT', 'pr', 'PPT', 'ppt', 'p', 'P', 'precip', 'PRECIP', 'tp', 'prcp', 'prate')\n",
      "<xarray.DataArray 'pr' (time: 3012, lat: 192, lon: 288)>\n",
      "dask.array<open_dataset-2fe5182f4f9a43ea4e824c922ae7fd72pr, shape=(3012, 192, 288), dtype=float32, chunksize=(3012, 192, 288), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * lat      (lat) float64 -90.0 -89.06 -88.12 -87.17 ... 87.17 88.12 89.06 90.0\n",
      "  * lon      (lon) float64 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * time     (time) object 1850-01-16 12:00:00 ... 2100-12-16 12:00:00\n",
      "Attributes:\n",
      "    standard_name:   precipitation_flux\n",
      "    long_name:       precipitation_flux\n",
      "    units:           kg m-2 s-1\n",
      "    comment:         Created using NCL code\n",
      "    cell_methods:    time: mean (interval: 1 month)\n",
      "    history:         (PRECC+PRECL)*r[h2o]\n",
      "    original_units:  m-1 s-1\n",
      "    original_name:   PRECC, PRECL\n",
      "    _FillValue:      1e+20\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'eeeeeeeeee' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 66\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#            print('Reading in: '+rn_syear[gg]+' '+rn_eyear[gg]+' '+vn)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m             farr \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39mdata_read_in_3D(fils2,rn_syear[gg],rn_eyear[gg],vn)\n\u001b[0;32m---> 66\u001b[0m             \u001b[43meeeeeeeeee\u001b[49m\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m (gg\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     68\u001b[0m                 em \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mzeros_like(farr)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eeeeeeeeee' is not defined"
     ]
    }
   ],
   "source": [
    "# not using netCDF operator ncea here as data for one run (for one variable) can be strung across multiple files\n",
    "\n",
    "vlist = ['prect','psl','trefht','ts','ssh']\n",
    "\n",
    "for vn in vlist:\n",
    "    names = []\n",
    "    paths = []\n",
    "    syear = []\n",
    "    eyear = []\n",
    "    names_EM = []\n",
    "    EM_num = []\n",
    "    \n",
    "#    print(vn)\n",
    "    with open('../namelist_byvar/namelist_'+vn) as f:\n",
    "        for line in f:\n",
    "            check = line.split(' | ')\n",
    "            if check[0].rstrip('\\r\\n')=='missing':\n",
    "                names.append(check[0].rstrip('\\r\\n'))\n",
    "                paths.append(check[0].rstrip('\\r\\n'))\n",
    "                syear.append(check[0].rstrip('\\r\\n'))\n",
    "                eyear.append(check[0].rstrip('\\r\\n'))\n",
    "                EM_num.append(-1)\n",
    "                names_EM.append(check[0].rstrip('\\r\\n'))\n",
    "            else:\n",
    "                names.append(check[0])\n",
    "                paths.append(check[1])\n",
    "                syear.append(check[2])\n",
    "                eyear.append(check[3])\n",
    "                ems = check[4].split('-')\n",
    "                EM_num.append(ems[0])\n",
    "                names_EM.append(ems[1].rstrip('\\r\\n'))\n",
    "\n",
    "    EM_numI = np.array(EM_num).astype(int)\n",
    "    EM_numI_max = EM_numI.max()\n",
    "    print(type(EM_numI_max))\n",
    "    \n",
    "    for x in range(1, EM_numI_max+1):\n",
    "        rn = np.array(paths)[np.where(EM_numI == x)]\n",
    "        rn_syear = np.array(syear)[np.where(EM_numI == x)]\n",
    "        rn_eyear = np.array(eyear)[np.where(EM_numI == x)]\n",
    "        rn_names_EM = np.array(names_EM)[np.where(EM_numI == x)] \n",
    "        \n",
    "        fno = rn_names_EM[0].rstrip('\\r\\n')+'.cvdp_data.'+vn+'.ensemble_mean.'+rn_syear[0]+'-'+rn_eyear[0]+'.nc'\n",
    "        fno = fno.replace(' ','_')\n",
    "        print(fno)\n",
    "        if os.path.exists(fno):\n",
    "            print(fno+\" already created\")\n",
    "            break\n",
    "\n",
    "        if not all(y==rn_syear[0] for y in rn_syear):\n",
    "            print(\"Not all start years are the same for the \"+rn_names_EM[0].rstrip('\\r\\n')+\" ensemble for \"+vn+\", not creating ensemble mean, exiting\")\n",
    "            break\n",
    "        if not all(y==rn_eyear[0] for y in rn_eyear):\n",
    "            print(\"Not all end years are the same for the \"+rn_names_EM[0].rstrip('\\r\\n')+\" ensemble for \"+vn+\", not creating ensemble mean, exiting\")\n",
    "            break\n",
    "\n",
    "        gg = 0        \n",
    "        for mr in rn:\n",
    "            fils2 = glob.glob(mr)\n",
    "#            print('Reading in: '+rn_syear[gg]+' '+rn_eyear[gg]+' '+vn)\n",
    "            farr = func.data_read_in_3D(fils2,rn_syear[gg],rn_eyear[gg],vn)\n",
    "            eeeeeeeeee\n",
    "            if (gg==0):\n",
    "                em = xr.zeros_like(farr)\n",
    "                em_cntr = xr.zeros_like(farr)\n",
    "                source_attrs = farr.attrs\n",
    "            em = em+farr\n",
    "            em_cntr = em_cntr+xr.where(farr.isnull()==False,1,0)   \n",
    "            print(np.min(em_cntr))\n",
    "            gg = gg+1\n",
    "\n",
    "#        print(np.max(em))\n",
    "#        em = em/float(gg)\n",
    "        em = em/em_cntr\n",
    "#        print(np.max(em))\n",
    "        \n",
    "        em.attrs = source_attrs\n",
    "#        print(em)\n",
    "        em.name = vn\n",
    "        em.to_netcdf(fno,encoding={vn:{'dtype':'float32'}, 'lat':{'dtype':'float32','_FillValue': None}, 'lon':{'dtype':'float32','_FillValue': None}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5869ba-2ddd-4b0a-bdce-9163dd55f14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8ba151-fff2-4d1a-96e1-949f90c6319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for x in range(1, 5):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b24e5e-6a97-4927-b336-d95826757efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
